{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from os import path, getcwd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/warringt'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOP_LEVEL_DIR = getcwd()\n",
    "TOP_LEVEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8660"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "API_PORT = 8660\n",
    "API_PORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PARAMS = {\n",
    "    \"args\" : [], # Extra command line args for loading the model\n",
    "\n",
    "    # LLaVA 1.5-13B\n",
    "\n",
    "    # 8 bits\n",
    "    #\"model_name\": \"TheBloke/llava-v1.5-13B-GPTQ:gptq-8bit-32g-actorder_True\",\n",
    "    #\"model\": \"TheBloke_llava-v1.5-13B-GPTQ_gptq-8bit-32g-actorder_True\",\n",
    "\n",
    "    # 4 bits\n",
    "    #\"model_name\": \"TheBloke/llava-v1.5-13B-GPTQ:gptq-4bit-32g-actorder_True\",\n",
    "    #\"model\": \"TheBloke_llava-v1.5-13B-GPTQ_gptq-4bit-32g-actorder_True\",\n",
    "\n",
    "    # 4 bits - 128g - actorder_True\n",
    "    #\"model_name\": \"TheBloke/llava-v1.5-13B-GPTQ\",\n",
    "    #\"model\": \"TheBloke_llava-v1.5-13B-GPTQ\",\n",
    "\n",
    "    #\"args\": []\n",
    "    #\"pipeline\": \"llava-v1.5-13b\"\n",
    "\n",
    "\n",
    "    # MiniGPT-v4 w/ Vicuna v0 13B backend\n",
    "\n",
    "    \"model_name\": \"j-min/vicuna-13b-v0-merged\",\n",
    "    \"model\": \"j-min_vicuna-13b-v0-merged\",\n",
    "    \n",
    "    # 8 bits\n",
    "    #\"model_name\": \"\",\n",
    "    #\"model\": \"\",\n",
    "\n",
    "    # 4 bits\n",
    "    #\"model_name\": \"anon8231489123/vicuna-13b-GPTQ-4bit-128g\",\n",
    "    #\"model\": \"anon8231489123_vicuna-13b-GPTQ-4bit-128g\",\n",
    "    #\"args\": [\"--wbits\", \"4\", \"--groupsize\", \"128\"],\n",
    "    \n",
    "    \"pipeline\": \"minigpt4-13b\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'args'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m SERVER_CMD \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbash\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_linux.sh\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--model\u001b[39m\u001b[38;5;124m\"\u001b[39m, MODEL_PARAMS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--multimodal-pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, MODEL_PARAMS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpipeline\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--disable_exllama\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--loader autogptq\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--no_inject_fused_attention\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m# Fused attention causes an error\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--api\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--api-port\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mAPI_PORT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[43mMODEL_PARAMS\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43margs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     10\u001b[0m ]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'args'"
     ]
    }
   ],
   "source": [
    "SERVER_CMD = [\n",
    "    \"bash\",\n",
    "    \"start_linux.sh\",\n",
    "    \"--model\", MODEL_PARAMS['model'],\n",
    "    \"--multimodal-pipeline\", MODEL_PARAMS['pipeline'],\n",
    "    \"--disable_exllama\",\n",
    "    \"--loader autogptq\", \"--no_inject_fused_attention\", # Fused attention causes an error\n",
    "    \"--api\", \"--api-port\", f\"{API_PORT}\",\n",
    "    *MODEL_PARAMS[\"args\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCRIPT_NAME = \"run_vqav2_val_\" + MODEL_PARAMS['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "noconvert"
    ]
   },
   "outputs": [],
   "source": [
    "SCITAS_PARAMS = f\"\"\"#!/bin/bash -l\n",
    "\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --time 36:00:00\n",
    "#SBATCH --cpus-per-task=10\n",
    "#SBATCH --partition=gpu\n",
    "#SBATCH --qos=gpu\n",
    "#SBATCH --gres=gpu:2\n",
    "#SBATCH --mem 64G\n",
    "\n",
    "cd ~/tgw\n",
    "{' '.join(SERVER_CMD)} &\n",
    "cd ~/\n",
    "ipython {SCRIPT_NAME}.py\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "noconvert"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook run_vqav2.ipynb to script\n",
      "[NbConvertApp] Writing 4094 bytes to run_vqav2_val_anon8231489123_vicuna-13b-GPTQ-4bit-128g.py\n"
     ]
    }
   ],
   "source": [
    "# Generate SCITAS job script\n",
    "with open(f'{SCRIPT_NAME}.run', 'w+') as job_file:\n",
    "    job_file.write(SCITAS_PARAMS)\n",
    "\n",
    "# Generate actual python script\n",
    "!jupyter nbconvert --to script run_vqav2.ipynb --output {SCRIPT_NAME} \\\n",
    "    -TagRemovePreprocessor.enabled=True --TagRemovePreprocessor.remove_cell_tags noconvert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/warringt/qvlm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>question</th>\n",
       "      <th>question_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>262148</td>\n",
       "      <td>Where is he looking?</td>\n",
       "      <td>262148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>262148</td>\n",
       "      <td>What are the people in the background doing?</td>\n",
       "      <td>262148001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>262148</td>\n",
       "      <td>What is he on top of?</td>\n",
       "      <td>262148002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>393225</td>\n",
       "      <td>What website copyrighted the picture?</td>\n",
       "      <td>393225000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>393225</td>\n",
       "      <td>Is this a creamy soup?</td>\n",
       "      <td>393225001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214349</th>\n",
       "      <td>393212</td>\n",
       "      <td>What is the main color in the photo?</td>\n",
       "      <td>393212000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214350</th>\n",
       "      <td>393212</td>\n",
       "      <td>What is the meaning of this sign?</td>\n",
       "      <td>393212001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214351</th>\n",
       "      <td>393212</td>\n",
       "      <td>What is on the sign?</td>\n",
       "      <td>393212002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214352</th>\n",
       "      <td>393212</td>\n",
       "      <td>Does the arrow point left or right?</td>\n",
       "      <td>393212003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214353</th>\n",
       "      <td>393212</td>\n",
       "      <td>Is the sign for traffic?</td>\n",
       "      <td>393212004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214354 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        image_id                                      question  question_id\n",
       "0         262148                          Where is he looking?    262148000\n",
       "1         262148  What are the people in the background doing?    262148001\n",
       "2         262148                         What is he on top of?    262148002\n",
       "3         393225         What website copyrighted the picture?    393225000\n",
       "4         393225                        Is this a creamy soup?    393225001\n",
       "...          ...                                           ...          ...\n",
       "214349    393212          What is the main color in the photo?    393212000\n",
       "214350    393212             What is the meaning of this sign?    393212001\n",
       "214351    393212                          What is on the sign?    393212002\n",
       "214352    393212           Does the arrow point left or right?    393212003\n",
       "214353    393212                      Is the sign for traffic?    393212004\n",
       "\n",
       "[214354 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd {TOP_LEVEL_DIR}/qvlm\n",
    "\n",
    "#questions_path = 'datasets/VQA_V2/v2_Questions_Test_mscoco/v2_OpenEnded_mscoco_test2015_questions.json'\n",
    "questions_path = 'datasets/VQA_V2/v2_OpenEnded_mscoco_val2014_questions.json'\n",
    "questions_json = json.load(open(questions_path))\n",
    "questions_df = pd.DataFrame(questions_json['questions'])\n",
    "questions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Launching the model server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/warringt/tgw\n"
     ]
    }
   ],
   "source": [
    "%cd {TOP_LEVEL_DIR}/tgw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/warringt/tgw\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import subprocess\n",
    "%cd {TOP_LEVEL_DIR}/tgw\n",
    "\n",
    "def get_model_server_process(params: dict):\n",
    "  if (not path.exists(params['model'])):\n",
    "    !python download-model.py {params['model_name']}\n",
    "  return lambda: subprocess.run(SERVER_CMD, check=True, shell=True, close_fds=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/warringt/qvlm\n"
     ]
    }
   ],
   "source": [
    "%cd {TOP_LEVEL_DIR}/qvlm\n",
    "\n",
    "import socket,time\n",
    "from eval.connectors import Connector\n",
    "\n",
    "def wait_for_port(connector: Connector, delay: int = 3, max_retries: int = 1000):\n",
    "  sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "  conn_info = (connector.url, connector.port)\n",
    "  result = sock.connect_ex(conn_info)\n",
    "  counter = max_retries\n",
    "  while (counter >= 0 and result != 0):\n",
    "    print(f\"Port is not open, retrying in {delay}s...\\t({max_retries - counter}/{max_retries})\")\n",
    "    time.sleep(delay)\n",
    "    result = sock.connect_ex(conn_info)\n",
    "    counter = counter - 1\n",
    "  \n",
    "  if (result == 0):\n",
    "    print(\"Port is open!\")\n",
    "    sock.close()\n",
    "  else:\n",
    "    print(f\"Port was not open after n={max_retries} max retries\")\n",
    "    sock.close()\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/warringt/tgw\n",
      "Downloading the model to models/TheBloke_llava-v1.5-13B-GPTQ_gptq-8bit-32g-actorder_True\n"
     ]
    }
   ],
   "source": [
    "#%cd {TOP_LEVEL_DIR}/tgw\n",
    "# Do not uncomment, this doesn't work yet\n",
    "#threading.Thread(target=get_model_server_process(PARAMS), daemon=True).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Computing the responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/warringt/qvlm\n"
     ]
    }
   ],
   "source": [
    "%cd {TOP_LEVEL_DIR}/qvlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from eval.connectors.llamafile import LlamafileConnector\n",
    "from eval.connectors.textgenerationwebui import TextGenerationWebUIConnector\n",
    "\n",
    "connector = TextGenerationWebUIConnector('localhost', API_PORT, prompt_format = '{prompt}\\nAnswer with a single word or phrase.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Port is not open, retrying in 3s...\t(0/200)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m VQAV2Evaluator(questions_df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m100\u001b[39m))\n\u001b[1;32m      4\u001b[0m evaluator\u001b[38;5;241m.\u001b[39mconnect(connector)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mwait_for_port\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m60\u001b[39m) \u001b[38;5;66;03m# The server can take some time to keep booting after the port has been opened...\u001b[39;00m\n\u001b[1;32m      8\u001b[0m evaluator\u001b[38;5;241m.\u001b[39mget_responses(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatasets/VQA_V2/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPARAMS[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_responses.jsonl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m, in \u001b[0;36mwait_for_port\u001b[0;34m(connector, delay, max_retries)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (counter \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m result \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     12\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPort is not open, retrying in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdelay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms...\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_retries\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mcounter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_retries\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m   \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelay\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m   result \u001b[38;5;241m=\u001b[39m sock\u001b[38;5;241m.\u001b[39mconnect_ex(conn_info)\n\u001b[1;32m     15\u001b[0m   counter \u001b[38;5;241m=\u001b[39m counter \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from eval.evaluation.VQAV2 import VQAV2Evaluator\n",
    "\n",
    "evaluator = VQAV2Evaluator(questions_df, img_dir='datasets/VQA_V2/val2014')\n",
    "evaluator.connect(connector)\n",
    "\n",
    "wait_for_port(connector, delay=3, max_retries = 200)\n",
    "time.sleep(30) # The server can take some time to keep booting after the port has been opened...\n",
    "evaluator.get_responses(f'datasets/VQA_V2/val_{MODEL_PARAMS[\"model\"]}_responses.jsonl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm_q",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
