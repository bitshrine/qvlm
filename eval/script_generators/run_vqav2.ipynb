{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from os import path, getcwd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kepler/Documents/EPFL/MA6/Project/qvlm/eval/script_generators'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOP_LEVEL_DIR = getcwd()\n",
    "TOP_LEVEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8660"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "API_PORT = 8660\n",
    "API_PORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PARAMS = {\n",
    "    # LLaVA 1.5-13B\n",
    "\n",
    "    # 8 bits\n",
    "    #\"model_name\": \"TheBloke/llava-v1.5-13B-GPTQ:gptq-8bit-32g-actorder_True\",\n",
    "    #\"model\": \"TheBloke_llava-v1.5-13B-GPTQ_gptq-8bit-32g-actorder_True\",\n",
    "\n",
    "    # 4 bits\n",
    "    #\"model_name\": \"TheBloke/llava-v1.5-13B-GPTQ:gptq-4bit-32g-actorder_True\",\n",
    "    #\"model\": \"TheBloke_llava-v1.5-13B-GPTQ_gptq-4bit-32g-actorder_True\",\n",
    "\n",
    "    # 4 bits - 128g - actorder_True\n",
    "    \"model_name\": \"TheBloke/llava-v1.5-13B-GPTQ\",\n",
    "    \"model\": \"TheBloke_llava-v1.5-13B-GPTQ\",\n",
    "\n",
    "\n",
    "    \"pipeline\": \"llava-v1.5-13b\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVER_CMD = [\n",
    "    \"bash\",\n",
    "    \"start_linux.sh\",\n",
    "    \"--model\", MODEL_PARAMS['model'],\n",
    "    \"--multimodal-pipeline\", MODEL_PARAMS['pipeline'],\n",
    "    \"--disable_exllama\",\n",
    "    \"--loader autogptq\", \"--no_inject_fused_attention\", # Fused attention causes an error\n",
    "    \"--api\", \"--api-port\", f\"{API_PORT}\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "noconvert"
    ]
   },
   "outputs": [],
   "source": [
    "SCITAS_PARAMS = f\"\"\"\n",
    "#!/bin/bash -l\n",
    "\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --time 36:00:00\n",
    "#SBATCH --cpus-per-task=10\n",
    "#SBATCH --partition=gpu\n",
    "#SBATCH --qos=gpu\n",
    "#SBATCH --gres=gpu:2\n",
    "#SBATCH --mem 64G\n",
    "\n",
    "cd ~/tgw\n",
    "{' '.join(SERVER_CMD)} &\n",
    "cd ~/\n",
    "ipython run_vqav2_TheBloke_llava-v1.5-13B-GPTQ_gptq-4bit-32g-actorder_True.py\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "noconvert"
    ]
   },
   "outputs": [],
   "source": [
    "SCRIPT_NAME = \"run_vqav2_\" + MODEL_PARAMS['model']\n",
    "# Generate SCITAS job script\n",
    "with open(f'{SCRIPT_NAME}.run', 'w+') as job_file:\n",
    "    job_file.write(SCITAS_PARAMS)\n",
    "\n",
    "# Generate actual python script\n",
    "!jupyter nbconvert --to script run_vqav2.ipynb --output {SCRIPT_NAME}.py \\\n",
    "    -TagRemovePreprocessor.enabled=True --TagRemovePreprocessor.remove_cell_tags noconvert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/warringt/qvlm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>question</th>\n",
       "      <th>question_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>262144</td>\n",
       "      <td>What credit card company is on the banner in t...</td>\n",
       "      <td>262144005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>262144</td>\n",
       "      <td>Is the pitcher wearing a hat?</td>\n",
       "      <td>262144003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>262144</td>\n",
       "      <td>Is the ball flying towards the batter?</td>\n",
       "      <td>262144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>524289</td>\n",
       "      <td>Are the horses playing a game?</td>\n",
       "      <td>524289001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>524289</td>\n",
       "      <td>What is the color of water in the image?</td>\n",
       "      <td>524289002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107389</th>\n",
       "      <td>406773</td>\n",
       "      <td>What is the giraffe resting its head on?</td>\n",
       "      <td>406773002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107390</th>\n",
       "      <td>444850</td>\n",
       "      <td>Why is the woman standing next to the truck?</td>\n",
       "      <td>444850001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107391</th>\n",
       "      <td>554649</td>\n",
       "      <td>Is this a police van?</td>\n",
       "      <td>554649022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107392</th>\n",
       "      <td>372707</td>\n",
       "      <td>Who is wearing their hat backwards?</td>\n",
       "      <td>372707007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107393</th>\n",
       "      <td>92983</td>\n",
       "      <td>What is the featured fabric material?</td>\n",
       "      <td>92983001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107394 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        image_id                                           question  \\\n",
       "0         262144  What credit card company is on the banner in t...   \n",
       "1         262144                      Is the pitcher wearing a hat?   \n",
       "2         262144             Is the ball flying towards the batter?   \n",
       "3         524289                     Are the horses playing a game?   \n",
       "4         524289           What is the color of water in the image?   \n",
       "...          ...                                                ...   \n",
       "107389    406773           What is the giraffe resting its head on?   \n",
       "107390    444850       Why is the woman standing next to the truck?   \n",
       "107391    554649                              Is this a police van?   \n",
       "107392    372707                Who is wearing their hat backwards?   \n",
       "107393     92983              What is the featured fabric material?   \n",
       "\n",
       "        question_id  \n",
       "0         262144005  \n",
       "1         262144003  \n",
       "2         262144000  \n",
       "3         524289001  \n",
       "4         524289002  \n",
       "...             ...  \n",
       "107389    406773002  \n",
       "107390    444850001  \n",
       "107391    554649022  \n",
       "107392    372707007  \n",
       "107393     92983001  \n",
       "\n",
       "[107394 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd {TOP_LEVEL_DIR}/qvlm\n",
    "\n",
    "questions_path = 'datasets/VQA_V2/v2_Questions_Test_mscoco/v2_OpenEnded_mscoco_test-dev2015_questions.json'\n",
    "questions_json = json.load(open(questions_path))\n",
    "questions_df = pd.DataFrame(questions_json['questions'])\n",
    "questions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Launching the model server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/warringt/tgw\n"
     ]
    }
   ],
   "source": [
    "%cd {TOP_LEVEL_DIR}/tgw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/warringt/tgw\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import subprocess\n",
    "%cd {TOP_LEVEL_DIR}/tgw\n",
    "\n",
    "def get_model_server_process(params: dict):\n",
    "  if (not path.exists(params['model'])):\n",
    "    !python download-model.py {params['model_name']}\n",
    "  return lambda: subprocess.run(SERVER_CMD, check=True, shell=True, close_fds=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/warringt/qvlm\n"
     ]
    }
   ],
   "source": [
    "%cd {TOP_LEVEL_DIR}/qvlm\n",
    "\n",
    "import socket,time\n",
    "from eval.connectors import Connector\n",
    "\n",
    "def wait_for_port(connector: Connector, delay: int = 3, max_retries: int = 1000):\n",
    "  sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "  conn_info = (connector.url, connector.port)\n",
    "  result = sock.connect_ex(conn_info)\n",
    "  counter = max_retries\n",
    "  while (counter >= 0 and result != 0):\n",
    "    print(f\"Port is not open, retrying in {delay}s...\\t({max_retries - counter}/{max_retries})\")\n",
    "    time.sleep(delay)\n",
    "    result = sock.connect_ex(conn_info)\n",
    "    counter = counter - 1\n",
    "  \n",
    "  if (result == 0):\n",
    "    print(\"Port is open!\")\n",
    "    sock.close()\n",
    "  else:\n",
    "    print(f\"Port was not open after n={max_retries} max retries\")\n",
    "    sock.close()\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/warringt/tgw\n",
      "Downloading the model to models/TheBloke_llava-v1.5-13B-GPTQ_gptq-8bit-32g-actorder_True\n"
     ]
    }
   ],
   "source": [
    "#%cd {TOP_LEVEL_DIR}/tgw\n",
    "# Do not uncomment, this doesn't work yet\n",
    "#threading.Thread(target=get_model_server_process(PARAMS), daemon=True).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Computing the responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/warringt/qvlm\n"
     ]
    }
   ],
   "source": [
    "%cd {TOP_LEVEL_DIR}/qvlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from eval.connectors.llamafile import LlamafileConnector\n",
    "from eval.connectors.textgenerationwebui import TextGenerationWebUIConnector\n",
    "\n",
    "connector = TextGenerationWebUIConnector('localhost', API_PORT, prompt_format = '{prompt}\\nAnswer with a single word or phrase.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Port is not open, retrying in 3s...\t(0/200)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m VQAV2Evaluator(questions_df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m100\u001b[39m))\n\u001b[1;32m      4\u001b[0m evaluator\u001b[38;5;241m.\u001b[39mconnect(connector)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mwait_for_port\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m60\u001b[39m) \u001b[38;5;66;03m# The server can take some time to keep booting after the port has been opened...\u001b[39;00m\n\u001b[1;32m      8\u001b[0m evaluator\u001b[38;5;241m.\u001b[39mget_responses(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatasets/VQA_V2/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPARAMS[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_responses.jsonl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m, in \u001b[0;36mwait_for_port\u001b[0;34m(connector, delay, max_retries)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (counter \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m result \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     12\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPort is not open, retrying in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdelay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms...\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_retries\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mcounter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_retries\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m   \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelay\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m   result \u001b[38;5;241m=\u001b[39m sock\u001b[38;5;241m.\u001b[39mconnect_ex(conn_info)\n\u001b[1;32m     15\u001b[0m   counter \u001b[38;5;241m=\u001b[39m counter \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from eval.evaluation.VQAV2 import VQAV2Evaluator\n",
    "\n",
    "evaluator = VQAV2Evaluator(questions_df.head(100))\n",
    "evaluator.connect(connector)\n",
    "\n",
    "wait_for_port(connector, delay=3, max_retries = 200)\n",
    "time.sleep(30) # The server can take some time to keep booting after the port has been opened...\n",
    "evaluator.get_responses(f'datasets/VQA_V2/{MODEL_PARAMS[\"model\"]}_responses.jsonl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm_q",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
